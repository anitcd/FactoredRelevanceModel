/**
 * TODO: queryField[] is not used. 
 * It works on only the title of the query.
 */
package searcher;

import RelevanceFeedback.NewScore;
import static common.CommonVariables.FIELD_FULL_BOW;
import static common.CommonVariables.FIELD_ID;
import common.TRECQuery;
import common.TRECQueryParser;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.Properties;
import java.util.logging.Level;
import java.util.logging.Logger;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.core.KeywordAnalyzer;
import org.apache.lucene.analysis.en.EnglishAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.BlendedTermQuery.Builder;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.TopScoreDocCollector;
import org.apache.lucene.search.similarities.AfterEffect;
import org.apache.lucene.search.similarities.AfterEffectB;
import org.apache.lucene.search.similarities.AfterEffectL;
import org.apache.lucene.search.similarities.BM25Similarity;
import org.apache.lucene.search.similarities.BasicModel;
import org.apache.lucene.search.similarities.BasicModelBE;
import org.apache.lucene.search.similarities.BasicModelD;
import org.apache.lucene.search.similarities.BasicModelG;
import org.apache.lucene.search.similarities.BasicModelIF;
import org.apache.lucene.search.similarities.BasicModelIn;
import org.apache.lucene.search.similarities.BasicModelIne;
import org.apache.lucene.search.similarities.BasicModelP;
import org.apache.lucene.search.similarities.DFRSimilarity;
import org.apache.lucene.search.similarities.DefaultSimilarity;
import org.apache.lucene.search.similarities.LMDirichletSimilarity;
import org.apache.lucene.search.similarities.LMJelinekMercerSimilarity;
import org.apache.lucene.search.similarities.MultiSimilarity;
import org.apache.lucene.search.similarities.Normalization;
import org.apache.lucene.search.similarities.Normalization.NoNormalization;
import org.apache.lucene.search.similarities.NormalizationH1;
import org.apache.lucene.search.similarities.NormalizationH2;
import org.apache.lucene.search.similarities.NormalizationH3;
import org.apache.lucene.search.similarities.NormalizationZ;
import org.apache.lucene.search.similarities.Similarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;

/**
 *
 * @author dwaipayan
 */
public class WebDocSearcher {

    String          propPath;
    Properties      prop;
    IndexReader     indexReader;
    IndexSearcher   indexSearcher;
    String          indexPath;
    File            indexFile;
    String          stopFilePath;
    String          queryPath;
    File            queryFile;      // the query file
    int             queryFieldFlag; // 1. title; 2. +desc, 3. +narr
    String          []queryFields;  // to contain the fields of the query to be used for search
    Analyzer        analyzer;
    Analyzer    webDocAnalyzer;           // webDocAnalyzer

    String          runName;
    int             numHits;
    boolean         boolIndexExists;
    String          resPath;        // path of the res file
    FileWriter      resFileWriter;  // the res file writer
    List<TRECQuery> queries;
    TRECQueryParser trecQueryparser;
    String          fieldToSearch;
    int             simFuncChoice;
    float           param1, param2, param3, param4;
    
    List<String []> W2Vmodel; // To store all the terms and their (200D) vectors, generated by Word2vec
    int             nW2V; // Size of W2V model i.e. #terms in the corpus (in .vec file)

    public WebDocSearcher(String propPath) throws IOException, Exception {

        this.propPath = propPath;
        prop = new Properties();
        try {
            prop.load(new FileReader(propPath));
        } catch (IOException ex) {
            System.err.println("Error: Properties file missing in "+propPath);
            System.exit(1);
        }
        //----- Properties file loaded

        // +++++ setting the analyzer with English Analyzer with Smart stopword list
        stopFilePath = prop.getProperty("stopFilePath");
        System.out.println("stopFilePath set to: " + stopFilePath);
        common.EnglishAnalyzerWithSmartStopword engAnalyzer = new common.EnglishAnalyzerWithSmartStopword(stopFilePath);
        analyzer = engAnalyzer.setAndGetEnglishAnalyzerWithSmartStopword();
        // ----- analyzer set: analyzer
        webDocAnalyzer = new common.WebDocAnalyzer();

        //+++++ index path setting 
        indexPath = prop.getProperty("indexPath");
        System.out.println("indexPath set to: " + indexPath);
        indexFile = new File(indexPath);
        Directory indexDir = FSDirectory.open(indexFile.toPath());

        if (!DirectoryReader.indexExists(indexDir)) {
            System.err.println("Index doesn't exists in "+indexPath);
            boolIndexExists = false;
            System.exit(1);
        }
        //----- index path set

        /* setting query path */
        queryPath = prop.getProperty("queryPath");
        System.out.println("queryPath set to: " + queryPath);
        queryFile = new File(queryPath);
        queryFieldFlag = Integer.parseInt(prop.getProperty("queryFieldFlag"));
        queryFields = new String[queryFieldFlag-1];
        /* query path set */
        // TODO: queryFields unused

        /* constructing the query */
        fieldToSearch = prop.getProperty("fieldToSearch", FIELD_FULL_BOW);
        System.out.println("Searching field for retrieval: " + fieldToSearch);
        trecQueryparser = new TRECQueryParser(queryPath, analyzer, fieldToSearch);
        queries = constructQueries();
        /* constructed the query */

        simFuncChoice = Integer.parseInt(prop.getProperty("similarityFunction"));
        if (null != prop.getProperty("param1"))
            param1 = Float.parseFloat(prop.getProperty("param1"));
        if (null != prop.getProperty("param2"))
            param2 = Float.parseFloat(prop.getProperty("param2"));
        if (null != prop.getProperty("param3"))
            param3 = Float.parseFloat(prop.getProperty("param3"));
        if (null != prop.getProperty("param4"))
            param4 = Float.parseFloat(prop.getProperty("param4"));

        /* setting indexReader and indexSearcher */
        indexReader = DirectoryReader.open(FSDirectory.open(indexFile.toPath()));

        indexSearcher = new IndexSearcher(indexReader);
        setSimilarityFunction(simFuncChoice, param1, param2, param3, param4);

        setRunName_ResFileName();

        File fl = new File(resPath);
        //if file exists, delete it
        if(fl.exists())
            System.out.println(fl.delete());

        resFileWriter = new FileWriter(resPath, true);

        /* res path set */
        numHits = Integer.parseInt(prop.getProperty("numHits", "1000"));
    }

    private void setSimilarityFunction(int choice, float param1, float param2, float param3, float param4) {

        switch(choice) {
            case 0:
                indexSearcher.setSimilarity(new DefaultSimilarity());
                System.out.println("Similarity function set to DefaultSimilarity");
                break;
            case 1:
                indexSearcher.setSimilarity(new BM25Similarity(param1, param2));
                System.out.println("Similarity function set to BM25Similarity"
                    + " with parameters: " + param1 + " " + param2);
                break;
            case 2:
                indexSearcher.setSimilarity(new LMJelinekMercerSimilarity(param1));
                System.out.println("Similarity function set to LMJelinekMercerSimilarity"
                    + " with parameter: " + param1);
                break;
            case 3:
                indexSearcher.setSimilarity(new LMDirichletSimilarity(param1));
                System.out.println("Similarity function set to LMDirichletSimilarity"
                    + " with parameter: " + param1);
                break;
            case 4:
//                indexSearcher.setSimilarity(new DFRSimilarity(new BasicModelIF(), new AfterEffectB(), new NormalizationH2()));
                BasicModel bm;
                AfterEffect ae;
                Normalization nor;
                switch((int)param1){
                    case 1:
                        bm = new BasicModelBE();
                        break;
                    case 2:
                        bm = new BasicModelD();
                        break;
                    case 3:
                        bm = new BasicModelG();
                        break;
                    case 4:
                        bm = new BasicModelIF();
                        break;
                    case 5:
                        bm = new BasicModelIn();
                        break;
                    case 6:
                        bm = new BasicModelIne();
                        break;
                    case 7:
                        bm = new BasicModelP();
                        break;
                    default:
                        bm = new BasicModelIF();
                        break;
                }
                switch ((int)param2){
                    case 1:
                        ae = new AfterEffectB();
                        break;
                    case 2:
                        ae = new AfterEffectL();
                        break;
                    default:
                        ae = new AfterEffectB();
                        break;
                }
                switch ((int)param3) {
                    case 1:
                        nor = new NormalizationH1();
                        break;
                    case 2:
                        nor = new NormalizationH2();
                        break;
                    case 3:
                        nor = new NormalizationH3();
                        break;
                    case 4:
                        nor = new NormalizationZ();
                        break;
                    case 5:
                        nor = new NoNormalization();
                        break;
                    default:
                        nor = new NormalizationH2();
                        break;
                }
//                bm = new BasicModelIF();
                indexSearcher.setSimilarity(new DFRSimilarity(bm, ae, nor));
                System.out.println("Similarity function set to DFRSimilarity with default parameters");
                break;
            case 5:
                Similarity[] sims = {
                        new BM25Similarity(param1, param2),
                        new LMJelinekMercerSimilarity(param3),
                        new LMDirichletSimilarity(param4),
                        //new DFRSimilarity(new BasicModelBE(), new AfterEffectB(), new NormalizationH1()),
                    };
                Similarity sim = new MultiSimilarity(sims);

                indexSearcher.setSimilarity(sim);
                System.out.println("Similarity function set to CombSUM(BM25, LM-JM, LM-Di)"
                    + " with parameters: k1=" + param1 + ", b=" + param2 + " (BM25); lamda=" + param3 + " (LM-JM); mu=" + param4 + " (LM-Di)");
                break;
        }
    }

    private void setRunName_ResFileName() {

        runName = queryFile.getName()+"-"+fieldToSearch+"-"+indexSearcher.getSimilarity(true).
            toString().replace(" ", "-").replace("(", "").replace(")", "");
        if(null == prop.getProperty("resPath"))
            resPath = "/home/dwaipayan/";
        else
            resPath = prop.getProperty("resPath");
        if(!resPath.endsWith("/"))
            resPath = resPath+"/";
        resPath = resPath+runName;
        System.out.println("Result will be stored in: "+resPath);
    }

    private List<TRECQuery> constructQueries() throws Exception {

        trecQueryparser.queryFileParse();
        return trecQueryparser.queries;
    }

//    class SearchResult {
//        ScoreDoc docScore;
//        Document doc;
//        SearchResult(ScoreDoc docScore, Document doc){
//            this.docScore = docScore;
//            this.doc = doc;
//        }
//    }
//    
//    public class ReRankAni implements Comparator<SearchResult> {
//        @Override
//        public int compare (SearchResult a, SearchResult b) {
//            return a.docScore.score>b.docScore.score?1:a.docScore.score==b.docScore.score?0:-1;
//        }
//    }
    public class sortScoreDoc implements Comparator<ScoreDoc> {
        @Override
        public int compare (ScoreDoc a, ScoreDoc b) {
            //return a.score>b.score?1:a.score==b.score?0:-1;   // standard sort (ascending order)
            return a.score<b.score?1:a.score==b.score?0:-1; // reverse order
        }
    }

    public class sortW2VModel implements Comparator<String []> {
        @Override
        public int compare (String a[], String b[]) {
            return a[0].compareTo(b[0])>0?1:a[0].compareTo(b[0])==0?0:-1;   // standard sort (ascending order)
            //return a.score<b.score?1:a.score==b.score?0:-1; // reverse order
        }
    }
    
    public ScoreDoc[] retrieve(TRECQuery query) throws Exception {

        ScoreDoc[] hits = null;
        TopDocs topDocs = null;

        TopScoreDocCollector collector = TopScoreDocCollector.create(numHits);
        Query luceneQuery = trecQueryparser.getAnalyzedQuery(query, 1);
        Query cityQuery = new TermQuery(new Term("cityId", query.qcity));
        Query candidateQuery = new TermQuery(new Term("qQID", query.qid));
        //Query candidateQuery = trecQueryparser.getAnalyzedQuery(query, 3); // for parsing QID only
        
        PhraseQuery candidateQueryPhrase = new PhraseQuery();
        candidateQueryPhrase.add(new Term("qQID", query.qid));


        BooleanQuery booleanQuery = new BooleanQuery();
        booleanQuery.add(luceneQuery, BooleanClause.Occur.SHOULD);
        booleanQuery.add(cityQuery, BooleanClause.Occur.MUST); // City matching is MUST
        booleanQuery.add(candidateQuery, BooleanClause.Occur.MUST);
        
        //booleanQuery.add(candidateQueryPhrase, BooleanClause.Occur.MUST);


        //System.out.println("||||||||||||||||||||||||||||||||||||||||||\nluceneQuery: " + luceneQuery + "\n-----------------------------------------------------\nbooleanQuery: " + booleanQuery.toString() + "\n-----------------------------------------------------\ncityQuery: " + cityQuery.toString() + "\n-----------------------------------------------------\ncandidateQuery: " + candidateQuery.toString() + "\n||||||||||||||||||||||||||||||||||||||||||\n");


        System.out.println(query.qid+ ": " +luceneQuery.toString(fieldToSearch));

        //indexSearcher.search(luceneQuery, collector); // Formal query
        indexSearcher.search(booleanQuery, collector); // Formal query AND City matching
        topDocs = collector.topDocs();
        hits = topDocs.scoreDocs;


//        // Ani...
//        for (int i = 0; i < hits.length; ++i) {
//            if(hits[i].score <= 0.0) {
//                hits[i].score = 0.5f;
//            }
//        }
//        // Updating scores
//        reRankUsingKDE(hits, query);
//
//        // Sorting hits
//        Arrays.sort(hits, new sortScoreDoc());

        
        
//        for (int i = 0; i < hits.length; ++i) {
//            System.out.println("\nHITS: " + hits[i].doc + "\t" + hits[i].score);
//            System.out.println("TopDocs: " + topDocs.scoreDocs[i].doc + "\t" + topDocs.scoreDocs[i].score + "\n");
//        }

        
//        SearchResult []results = new SearchResult[hits.length];
//        
//        for (int i = 0; i < hits.length; ++i) {
//            results[i] = new SearchResult(hits[i], indexSearcher.doc(hits[i].doc));
//        }
        
//        Arrays.sort(results, new ReRankAni());


//        for (int i = 0; i < hits.length; ++i) {
//            hits[i] = results[i].docScore;
//        }
//

//        List<NewScore> finalList = new ArrayList<>();
//        Collections.sort(finalList, new Comparator<NewScore>(){
//            @Override
//            public int compare(NewScore t, NewScore t1) {
//                return t.score>t1.score?1:t.score==t1.score?0:-1;
//            }
//        });
//        Collections.sort(hits, new Comparator<ScoreDoc>(){
//            @Override
//            public int compare(ScoreDoc t, ScoreDoc t1) {
//                return t.score>t1.score?1:t.score==t1.score?0:-1;
//            }
//        });
        //.............
        
        if(hits == null)
            System.out.println("Nothing found");

        return hits;
    }
    
    public void reRankUsingKDE(ScoreDoc[] hits, TRECQuery query) throws Exception {
        Document[] docList = new Document[hits.length];
        double[] wArray = new double[hits.length]; // weight array
        double[] xArray = new double[hits.length]; // latitude array
        double[] yArray = new double[hits.length]; // longitude array
        
        
        for (int i = 0; i < hits.length; ++i) {
            docList[i] = indexSearcher.doc(hits[i].doc);
//            if(hits[i].score <= 0.0) {
//                hits[i].score = 0.5f;
//            }
//            
            // Get access to the location of each document
            //docList[i].get("lat"); /* or (same) */ // indexSearcher.doc(hits[i].doc).get("lat");
            //docList[i].get("lng"); /* or (same) */ // indexSearcher.doc(hits[i].doc).get("lng");

            //update the scores...
        //System.out.println("\nLat: " + docList[i].get("lat") + "\tLng:" + docList[i].get("lng") + "\n");
        }
        
//        for (int i = 0; i < hits.length; ++i) {
//            wArray[i]=hits[i].score;
//            xArray[i]=Double.parseDouble(docList[i].get("lat"));
//            yArray[i]=Double.parseDouble(docList[i].get("lng"));
//        }
        
        // n = 1 when estimating all docs based on the query (as each query has a single location point)
        wArray[0] = 1.0;
        xArray[0] = Double.parseDouble(query.qlat);
        yArray[0] = Double.parseDouble(query.qlng);

        for (int i = 0; i < hits.length; ++i) {
            hits[i].score = (float) KDEScore(Double.parseDouble(docList[i].get("lat")), Double.parseDouble(docList[i].get("lng")), xArray, yArray, wArray, 1, 1);
            System.out.println("Score: "+hits[i].score);
        }
    }
    
    // Returns estimated KDE score of (x, y) point based on (x_i, y_i) points where i=0, 1, ..., n-1
    // f_w(x) = 1/nh ∑w_i . K((x - x_i) / h) for i=1, 2, ..., n [weighted KDE with gaussian kernel function K(.), bandwidth h]
    public static double KDEScore(double x, double y, double[] xArray, double[] yArray, double[] wArray, int n, int h) {
        double latScore = 0.0, lngScore = 0.0, sigma, expPart;
        
        //expPart = Math.exp(-(Math.pow(distance(Double.parseDouble(x.get("lat")), Double.parseDouble(query.qlat), Double.parseDouble(x.get("lng")), Double.parseDouble(query.qlng), 0.0, 0.0), 2) / 2 * ));
        
        // Estimating latitude x
        sigma = variance(xArray, n);
        for (int i = 0; i < n; ++i) {
            expPart = Math.exp(-( Math.pow((x - xArray[i]), 2) / 2 * Math.pow(sigma, 2) * Math.pow(h, 2)));
            latScore += wArray[i] / (Math.sqrt(2 * Math.PI) * sigma) * expPart;
        }
        latScore /= (double)n * h;

        // Estimating longitude y
        sigma = variance(yArray, n);
        for (int i = 0; i < n; ++i) {
            expPart = Math.exp(-( Math.pow((y - yArray[i]), 2) / 2 * Math.pow(sigma, 2) * Math.pow(h, 2)));
            lngScore += wArray[i] / (Math.sqrt(2 * Math.PI) * sigma) * expPart;
        }
        lngScore /= (double)n * h;

        
        return latScore * lngScore;
    }
    
    static double variance(double a[], int n)
    {   double sum = 0.0, sqDiff = 0.0, var;
    
        if(n == 1) // You don't want to do this. Estimating a candidate data point based on a single pivot data point? (Think to generate random 3-4 coordinates)
            return 0.00001;
    
        for (int i = 0; i < n; i++)
            sum += a[i];
        double mean = (double)sum / (double)n;
        for (int i = 0; i < n; i++) 
            sqDiff += (a[i] - mean) * (a[i] - mean);
        
        //System.out.println("\n------------------------------------------\nn = " + n + "\tMean: " + mean + "\tsqDiff: " + sqDiff + "\tVar: " + (double)sqDiff / (n-1) + "\n------------------------------------------\n");
        var = (double)sqDiff / (n-1);
        
        if(var == 0.0)
            return 0.00001; // Returns a very small number, to keep the nature of the KDE equation intact.
        else
            return var;
    }    
    
/* Calculate distance between two points in latitude and longitude taking
 * into account height difference. If you are not interested in height
 * difference pass 0.0. Uses Haversine method as its base.
 * 
 * lat1, lon1 Start point lat2, lon2 End point el1 Start altitude in meters
 * el2 End altitude in meters
 * @returns Distance in Meters
 */
    public static double distance(double lat1, double lat2, double lon1,
double lon2, double el1, double el2) {

        final int R = 6371; // Radius of the earth

        double latDistance = Math.toRadians(lat2 - lat1);
        double lonDistance = Math.toRadians(lon2 - lon1);
        double a = Math.sin(latDistance / 2) * Math.sin(latDistance / 2)
                + Math.cos(Math.toRadians(lat1)) * Math.cos(Math.toRadians(lat2))
                * Math.sin(lonDistance / 2) * Math.sin(lonDistance / 2);
        double c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));
        double distance = R * c * 1000; // convert to meters

        double height = el1 - el2;

        distance = Math.pow(distance, 2) + Math.pow(height, 2);

        return Math.sqrt(distance);
    }
    
    public void loadW2Vmodel (String path) throws Exception { // Load Word2vec model

        File file = new File(path);
        FileReader fr = new FileReader(file);
        BufferedReader br = new BufferedReader(fr);
        String line;
        String[] keyTermVector = new String[201];
        //List<String []> W2Vmodel = new ArrayList<String []>();
        W2Vmodel = new ArrayList<String []>();
        nW2V = 0;
        while ((line = br.readLine()) != null) {
            W2Vmodel.add(nW2V, line.split(" "));
            nW2V++;
        }
        br.close();
        Collections.sort(W2Vmodel, new sortW2VModel());
        keyTermVector[0] = "beer";
        System.out.println(Collections.binarySearch(W2Vmodel, keyTermVector, new sortW2VModel()));
        //System.out.println(W2Vmodel.size() + "\t" + nW2V + "\t" + W2Vmodel.get(0).length);
//        for (int i = 0; i < nW2V; ++i) {
//            for (int j = 0; j < W2Vmodel.get(i).length; ++j) {
//                System.out.print(W2Vmodel.get(i)[j] + " ");
//            }
//            System.out.println("");
//        }
        System.exit(1);

        
//        int nDoc = indexReader.numDocs();
//        int nTopic = queries.size();
//        System.out.println("nTopic: " + nTopic);
//        for (int i = 0; i < nTopic; ++i) {
//            System.out.println("Query " + i + ": " + trecQueryparser.getAnalyzedQuery(queries.get(i), 1));
//        }
//        String content = indexSearcher.doc(0).getField("full-content").stringValue();
//        String[] terms = content.split(" ");
//        System.out.println("Content: " + terms.length);
//        String content1 = trecQueryparser.getAnalyzedQuery(queries.get(0), 1).toString();
//        String[] terms1 = content1.split(" ");
//        System.out.println("Content: " + terms1[1].replace("full-content:", ""));

        //System.out.println("Query: " + queries.get(0).qtitle);
//        System.out.println("Query: " + trecQueryparser.getAnalyzedQuery(queries.get(0), 1));
//        System.out.println("nDoc: " + nDoc);
//        System.out.println("ID: " + indexSearcher.doc(0).getField("docid").stringValue());
//        System.out.println("Content: " + indexSearcher.doc(0).getField("full-content").stringValue());
//        System.exit(1);
//        File file = new File("/store/TCD/TREC_CS/Wor2vec/trunk/64K_BOW_analysed");
//        file.createNewFile();
//        FileWriter writer = new FileWriter(file, true);
//        
//        for (int i = 0; i < nDoc; ++i) {
//            //Document doc = indexReader.document(i);
//            Document doc = indexSearcher.doc(i);
//            //System.out.println("Doc " + i + ": " + doc.getField("qQID").stringValue());
//            System.out.println("Doc: " + i + " Done!");
//            writer.write(doc.getField("full-content").stringValue() + " ");
//            writer.flush();
//        }
//        writer.close();
//        System.exit(1);
    }
    
    public void retrieveAll() throws Exception {
        
        loadW2Vmodel("/store/TCD/TREC_CS/Wor2vec/trunk/a"); // Ani: Loading Word2vec model "/store/TCD/TREC_CS/Wor2vec/trunk/64K_BOW_analysed_vectors.bin.vec"
        
        ScoreDoc[] hits = null;

        for (TRECQuery query : queries) {

            hits = retrieve(query);
            int hits_length = hits.length;
            System.out.println(query.qid + ": documents retrieve: " +hits_length);
            StringBuffer resBuffer = new StringBuffer();

            for (int i = 0; i < hits_length; ++i) {
                int luceneDocId = hits[i].doc;
                Document d = indexSearcher.doc(luceneDocId);
                resBuffer.append(query.qid).append("\tQ0\t").
                    append(d.get(FIELD_ID)).append("\t").
                    append((i)).append("\t").
                    append(hits[i].score).append("\t").
                    append(runName).append("\n");
                    //append(runName).append("\t").append(d.get("lat")).append("\n");
                    //append(runName).append("\t").append(query.qlat).append(", ").append(query.qlng).append("\n");
            }
            resFileWriter.write(resBuffer.toString());
        }
        resFileWriter.close();
        System.out.println("The result is saved in: "+resPath);

    }

    public static void main(String[] args) throws IOException, Exception {

        WebDocSearcher collSearcher = null;

        String usage = "java Wt10gSearcher <properties-file>\n"
            + "Properties file must contain:\n"
            + "1. indexPath: Path of the index\n"
            + "2. fieldToSearch: Name of the field to use for searching\n"
            + "3. queryPath: Path of the query file (in proper xml format)\n"
            + "4. queryFieldFlag: 1-title, 2-title+desc, 3-title+desc+narr\n"
            + "5. similarityFunction: 0.DefaultSimilarity, 1.BM25Similarity, 2.LMJelinekMercerSimilarity, 3.LMDirichletSimilarity\n"
            + "6. param1: \n"
            + "7. [param2]: optional if using BM25";

        /* // uncomment this if wants to run from inside Netbeans IDE
        args = new String[1];
        args[0] = "searcher.properties";
        //*/

        if(0 == args.length) {
            System.out.println(usage);
            System.exit(1);
        }

        System.out.println("Using properties file: "+args[0]);
        collSearcher = new WebDocSearcher(args[0]);

        collSearcher.retrieveAll();
    }

}
